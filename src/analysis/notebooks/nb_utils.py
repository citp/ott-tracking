import json
import urllib2
import pandas as pd
import ipaddress
from urlparse import urlparse
from tld import get_fld
from glob import glob
from os.path import join, sep


TSHARK_FIELD_SEP = "|"
ROKU_MACS = ["d8:31:34:22:e6:ff"]  # Roku MAC addresses to filter packets


def get_ps1_or_ipaddress(url):
    try:
        return get_fld(url, fail_silently=False)
    except Exception:
        hostname = urlparse(url).hostname
        try:
            ipaddress.ip_address(hostname)
            return hostname
        except Exception:
            return None


def read_extracted_fields(csv_path):
    """Read fields from txt files generated by tshark."""
    for l in open(csv_path):
        yield l.rstrip().split(TSHARK_FIELD_SEP)


def parse_roku_output_filename(filename):
    """Parse file names, which follows a specific pattern."""
    parts = filename.replace(".pcap.txt", "").split("-")
    channel_id, start_ts, command = parts[0:3]
    select_idx = parts[3] if command == "select" else 0
    return int(channel_id), int(start_ts), command, int(select_idx)


def read_pcap_fields_from_csvs(csv_dir, suffix=".csv"):
    for csv_path in glob(join(csv_dir, suffix)):
        filename = csv_path.split(sep)[-1]
        filename_wo_extension = filename.split(".")[0]
        # channel_id, start_ts, command, select_idx = parse_roku_output_filename(filename)
        channel_id, start_ts = filename_wo_extension.split("-")
        for pcap_fields in read_extracted_fields(csv_path):
            yield [channel_id, start_ts] + pcap_fields

# Download and parse Roku channel json - From Danny's notebook

CHANNEL_DATA_URL = 'https://iot-inspector.princeton.edu/pcaps/roku-channel-surfer/channel-list.txt'

def download_roku_channel_details(channel_data_url=CHANNEL_DATA_URL):
    channel_df = []
    for channel in urllib2.urlopen(CHANNEL_DATA_URL).read().split('\n'):
        if channel:
            channel_df.append(json.loads(channel))
    return pd.DataFrame(channel_df).set_index('id').sort_values("rankByWatched")
