import json
import urllib2
import pandas as pd
from urlparse import urlparse
from tld import get_fld
from glob import glob
from os.path import join, sep

TSHARK_FIELD_SEP = "|"
ROKU_MACS = ["d8:31:34:22:e6:ff"]  # Roku MAC addresses to filter packets


def get_ps1_or_ipaddress(url):
    try:
        return get_fld(url, fail_silently=False)
    except Exception:
        hostname = urlparse(url).hostname
        try:
            ipaddress.ip_address(hostname)
            return hostname
        except Exception:
            return None


def read_extracted_fields(txt_path):
    """Read fields from txt files generated by tshark."""
    fields = []
    for l in open(txt_path):        
        yield l.rstrip().split(TSHARK_FIELD_SEP)

def parse_roku_output_filename(filename):
    """Parse file names, which follows a specific pattern."""
    parts = filename.replace(".pcap.txt", "").split("-")
    channel_id, start_ts, command  = parts[0:3]
    select_idx  = parts[3] if command == "select" else 0
    return int(channel_id), int(start_ts), command, int(select_idx)

def read_pcap_fields_from_txts(txt_dir):
    all_fields = []
    for txt_path in glob(join(txt_dir, "*.txt")):
        filename = txt_path.split(sep)[-1]
        channel_id, start_ts, command, select_idx = parse_roku_output_filename(filename)
        for pcap_fields in read_extracted_fields(txt_path):
            yield [channel_id, start_ts, command, select_idx] + pcap_fields 

# Download and parse Roku channel json - From Danny's notebook

CHANNEL_DATA_URL = 'https://iot-inspector.princeton.edu/pcaps/roku-channel-surfer/channel-list.txt'

def download_roku_channel_details(channel_data_url=CHANNEL_DATA_URL):
    channel_df = []
    for channel in urllib2.urlopen(CHANNEL_DATA_URL).read().split('\n'):
        if channel:
            channel_df.append(json.loads(channel))
    return pd.DataFrame(channel_df).set_index('id').sort_values("rankByWatched")